# Modele-Neurone-1-Couche-Vectorise
## une intro aux r√©seaux de neurones

Le machine learning est un domaine de l'inteligence artificielle, qui consiste √† programmer une machine pour que celle-ci aprenne √† r√©aliser des t√¢ches en √©tudiant des exemples de ces derni√®res. Math√©matiquement, ces exemples sont repr√©sent√©s par des donn√©es que la machine utilise pour d√©velopper un mod√®le, par exemple f(x)=a.x+b, le but en machine learning, est de trouver les param√®tres a et b qui donnent le meilleur mod√®le possible, c-√†-d le mod√®le qui s'ajuste le mieux aux donn√©es. Pour cela, on programme dans la machine un algo d'optimisation qui va venir tester diff√©rentes valeurs de a et b jusqu'√† obtenir la combinaison de a et b qui minimise la distance entre le mod√®le et les donn√©es, c'est le machine learning : d√©velopper un mod√®le en se servant d'un algo d'optimisation pour minimiser les erreurs entre le mod√®le et nos donn√©es.

![image](https://user-images.githubusercontent.com/78855647/168451625-a76007c2-b0ac-4f86-88b9-052f2ee85149.png)

Les mod√®les sont infinis, on en peut citer : les mod√®les lin√©aires, Arbres de d√©cision, SVM (Support Vector Machine) ... et pour chaque mod√®le, on doit trouver un algo d'optimisation adapt√© :

![image](https://user-images.githubusercontent.com/78855647/168451644-d91af889-6554-422a-afa0-b4bb4ac75371.png)

### Deep learning :

![image](https://user-images.githubusercontent.com/78855647/168451663-ff84e3ec-3d76-4a0e-8b71-14d373411cca.png)

Domaine du machine learning, dans lequel au lieu de d√©velopper un des mod√®les que l'on vient de citer par exemple, on d√©veloppe √† la place des R√©seaux de Neurones Artificiels, le principe reste exactement le m√™me, c-√†-d que l'on fournit √† la machine des donn√©es, et √† l'aide d'un algo d'optimisation, on ajuste le mod√®le √† ces donn√©es, mais le mod√®le n'est pas une fonction explicite comme dans les cas d'avant, ici c'est un r√©seau de fonctions connect√©es les unes aux autres : un R√©seau de Neurones.

<img width="672" alt="image" src="https://user-images.githubusercontent.com/78855647/168451697-f8c57832-5ddd-4085-bb1d-7f703d0a5f3d.png">

*Remarque :* Plus le r√©seau est **profond** c-√†-d plus il contient des fonctions √† l'int√©rieur, plus la machine est capable de r√©aliser des t√¢ches complexes : reconnaitre des objets, identifier une personne sur une photo, conduire une voiture etc ... d'o√π l'on parle **d'apprentissage profond** ou **Deep Learning** lorsqu'on d√©veloppe des r√©seaux de neurones artificiels.

![image](https://user-images.githubusercontent.com/78855647/168451735-c2e881a1-d6ca-4688-bb44-a2c2f270d4cf.png)

### Histoire du deep learning :

Pour bien comprendre le fonctionnement des r√©seaux de neurones artificiels (RNA), on revient un peu sur l'origine de leur histoire, comment ils ont √©t√© invent√©, et qu'elles furent leurs √©volutions √† travers le temps, pour arriver √† la technologie que nous connaissons ajd'hui. Les 1ers RNA ont √©t√© invent√© en 1943 par 2 math√©maticiens et neuro scientifiques : Warren McCulloch et Walter Pitts, dans leur article intitul√© "A logical calculus of the ideas immanent in nervous activity ils expliquent comment ils ont cr√©es des neurones artificiels en s'inspirant des neurones biologiques.

<img width="551" alt="image" src="https://user-images.githubusercontent.com/78855647/168451776-8a99543f-2b0c-4e3c-862f-321418f98f2a.png">

En biologie, les neurones sont des cellules excitables connect√©es les unes aux autres et ayant pour r√¥le de transmettre des infos dans notre syst√®me nerveux. Chaque neurone est compos√© de plusieurs dendrites (portes d'entr√©e), d'un corps cellulaire, et d'un axone. Dendrites : c'est √† cet endroit au niveau de la synapse que le neurone re√ßoit des signaux lui provenant des neurones qui le pr√©c√®dent, ces signaux peuvent √™tre de type excitateur (+1) ou inhibiteur (-1). Lorsque la somme de ces signaux d√©passe un certain seuil, le neurone s'active, et produit alors un signal √©l√©ctrique, ce signal circule le long de l'axone en directions des terminaisons pour √™tre envoy√© √† son tour vers d'autres neurones de notre syst√®me nerveux, neurones qui fonctionneront exactement de la m√™me mani√®re.

Ce que Warren McCuloch et Walter Pitts ont essay√© de faire, c'est de mod√©liser ce fonctionnement en consid√©rant qu'un neurone pouvait √™tre repr√©sent√© par une ***fonction de transfert*** qui prend en entr√©e des signaux (x)·µ¢ et qui retourne une sortie y. A l'int√©reur de cette fonction, on trouve deux grandes √©tapes : 


1.   Agr√©gation : ùêü = ‚àë w·µ¢.x·µ¢
2.   Activation : y = 1 si f >= 0, et y = 0 sinon.

<img width="586" alt="image" src="https://user-images.githubusercontent.com/78855647/168451826-e7e77cce-9418-4fbe-ab0f-d68e471418e8.png">

Ce mod√®le historique d'un neurone artificiel est con√ßu pour traiter des entr√©es logiques (0 ou 1) d'o√π son appelation **Treshold Logic Unit**
Dans leur article, ils ont pu d√©montrer qu'avec ce mod√®le, on peut reproduire certaines fonctions logiques tel que la porte And, et la porte Or, ils ont √©gaement d√©montrer qu'en connectant plusieurs de ces fonctions les unes aux autres, un peu comme la mani√®re des neurones de notre cerveau, alors il serait possible de r√©soudre n'importe quel probl√®me de logique bool√©enne. Par contre ce mod√®le de deep leaning, ne dispose pas d'un algo d'apprentissage, et il faut donc trouver nous m√™me les valeurs des param√®tres w·µ¢ si l'on d√©sire s'en servir pour des applications du monde r√©el.
15 ans plutard, en 1957, Franck Rosenblatt (psycholoque am√©ricain) invente le ***Perceptron*** qui permet d'am√©liorer ces mod√©les de deep learning en proposant un 1er algorithme d'apprentissage de l'histoire du deep learning.

<img width="614" alt="image" src="https://user-images.githubusercontent.com/78855647/168451880-f7be4f1d-68f0-4efe-b6f2-e7871aa88207.png">

Suite √† √ßa, il y eu un engouement d√©mesur√© pour l'IA, on pensait qu'on pouvait gr√¢ce aux perceptrons d√©velopper des macines capables de lire, de parler.. et m√™me d'avoir une conscience, mais tous cet engouement s'effondra quelques ann√©es plus tard lorsqu'on s'est rendu compte que c'est faux, en partie prcq le perceptron est un mod√®le lin√©aire. On connut alors le 1er hiver de l'IA, o√π l'on a quasiment arr√™ter de financer les recherches en IA.

### Perceptron multi-couche (1986) :

Apr√®s cette 1ere p√©riode de froid, Geoffrey Hinton, l'un des p√®res du deep learning d√©veloppa en 1986 un Perceptron Multichouche, le 1er v√©ritable RNA

### Perceptron :

Le mod√®le de perceptron ressemble de tr√®s pr√®s au 1er mod√®le, et dispose d'un algo d'apprentissage lui permettant de trouver les valeurs des w·µ¢ afin de trouver les valeurs de sortie y qui nous conviennent.

<img width="638" alt="image" src="https://user-images.githubusercontent.com/78855647/168451934-6250f5cf-7214-4c85-ae42-4323fca5c3de.png">

Pour d√©velopper cet algo d'apprentissage, Rosenblatt s'est inspir√© de la th√©orie de Hebb :

<img width="628" alt="image" src="https://user-images.githubusercontent.com/78855647/168451945-9f4e27a9-7267-4149-b83e-f62f46438e4b.png">

A partir de cette id√©e de renforcement, Rosenblatt a d√©velopp√© un algo d'apprentissage qui consiste √† entrainer un neurone artificiel sur des *donn√©es de r√©f√©rence* (X,y) pour que celui ci renforce ces param√®tres W √† chaque fois qu'une entr√©e X est activ√©e en m√™me temps que la sortie y pr√©sente dans ces donn√©es, et pour √ßa il a imagin√© la formule suivante dans laquel W sont mis √† jour en calculant la diff√©rence entre la sortie de r√©f√©rence et la sortie produite par le neurone et en multipliant cette diff√©rence par la valeur de chaque entr√©e X ainsi que par un pas d'apprentissage positif \:

<img width="596" alt="image" src="https://user-images.githubusercontent.com/78855647/168451954-2ef818f2-b9de-46f4-bb36-31ef7a9d984b.png">

De cette mani√®re, si notre neurone produit une sortie diff√©rente de celle qu'il est cens√© produire, par exemple il nous sort y=0 alors qu'on veut y=1 alors notre formule donnera W=W+Œ±X, donc pour les entr√©es x qui valent 1, le co√©fficient W se verra augement√© d'un petit pas Œ±, il sera **renforc√©**, ce qui provoquera une augementation de la fonction f=w1.x1+w2.x2, et qui rapprochera donc notre neurone de son seuil d'activation.
Aussi longtemps que l'on sera en dessous de ce seuil, cad aussi longtemps que le neurone produira une mauvaise sortie, alors le co√©ff w continuera d'augementer gr√¢ce √† notre formule jusqu'au moment o√π y_true vaudra y et √† ce moment l√† notre formule donnera W=W+0, ce qui veut dire que nos param√®tres arr√™terons d'√©voluer. C'est ainsi que Rosenblatt a d√©velopp√© le 1er algo d'apprentissage de l'histoire du deep learning.

<img width="525" alt="image" src="https://user-images.githubusercontent.com/78855647/168451963-e90cae9d-604e-441c-a618-bef09c5d3344.png">

### Exemple de perceptron :

<img width="532" alt="image" src="https://user-images.githubusercontent.com/78855647/168451972-5503ceb0-7bc3-4e34-998b-7dbf0ba4e794.png">

Pour d√©terminer cette droite de d√©cision, √† l'aide d'un mod√®le lin√©aire, pertinent dans ce cas, on va fournir les valeurs x1 et x2 √† un neurone, et en multipliant chaque entr√©e du neurone par un poids W (w1, w2), dans ce neurone on va √©galement faire ppasser un co√©f compl√©mentaire qu'on appelle le biais, ce qui nous donne \:

<img width="537" alt="image" src="https://user-images.githubusercontent.com/78855647/168451986-b48e3d3a-c00b-4b5e-875e-9734e2021594.png">

Ce qui nous donne l'√©quation de la fronti√®re de d√©cision z(x1,x2)=0, qui s√©pare bien les deux groupes de donn√©es.

<img width="452" alt="image" src="https://user-images.githubusercontent.com/78855647/168452002-4f621867-547b-439f-8c70-6eba02a89f18.png">

Pour pr√©dire dans quelle classe appartient une future nouvelle plante, il va falloir r√©gler les param√®tres W et b pour s√©parer au mieux les deux classes, et d√©cider de l'appartenance de cette nouvelle plante selon le signe de z \:

<img width="552" alt="image" src="https://user-images.githubusercontent.com/78855647/168452020-38ff40f2-bba7-40b6-b0b6-02c10a1bb60b.png">

Pour am√©liorer ce mod√®le, ca serait d'accompagner chaque pr√©diction d'une probabilit√© d'appartenance, plus une plante sera √©loign√©e de la fronti√®re de d√©cision, plus il sera √©vident qu'elle appartienne bien √† sa classe, pour √ßa on pourrait utiliser une *fonction d'activation*, nous retournant une sortie qui s'appproche de 0 ou 1 au fur et au mesure que l'on s'√©loigne de la FD (z=0). Cette fonction est appel√© *fonction logistique* ou *sigmo√Æde*.

### Fonction Sigm√Æde (Logistique) :

Cette fonction permet de convertir la sortie z en une probabilit√© a(z) \: la proba de l'appartenance √† la classe 1,

<img width="527" alt="image" src="https://user-images.githubusercontent.com/78855647/168452042-4f3b1b46-f213-4c58-8e65-77a028a6176c.png">

Pour z=-2.1, a(z)=0.1, cette plante √† 10% de proba d'√™tre toxique (classe 1).
Pour z=1.4, a(z)=0.8, 80% d'√™tre toxique.

### Loi de Bernoulli :

Y suit une loi de Bernoulli : 

<img width="307" alt="image" src="https://user-images.githubusercontent.com/78855647/168452071-fcdba182-028c-4c4c-8917-83095693b1d0.png">

Pour r√©sumer, ce qu'on trouve √† l'int√©rieur d'un neuronne c'est une fonction lin√©aire z = w1.x1+w2.x2+b, suivi d'une fonction d'activation, la plus simple √©tant la fonction sigmo√Æde qui nus retourne une proba suivant une loi de Bernoulli.

<img width="541" alt="image" src="https://user-images.githubusercontent.com/78855647/168452550-35915c9d-dd21-4809-afcb-d8f9e2ad52b5.png">

Maintenant, notre but est de r√©gler les param√®tres W et b de fa√ßon √† obtenir le meilleur mod√®le possible, cad le mod√®le qui fait les plus petites erreurs entre les sorties a(z) et les vraies donn√©es Y. On va d√©finir une *fonction co√ªt* qui va permettre de mesurer ces erreurs.

### Fonction co√ªt (Vraisemblance dans ce cas) :

Une fonction co√ªt (loss function) permet de quantifier les erreurs effectu√©es par un mod√®le. Dans notre cas elle permettra de mesurer les distances suivantes \:

<img width="596" alt="image" src="https://user-images.githubusercontent.com/78855647/168452586-53d33902-bbdf-4482-9c47-4397ae81085f.png">

#### Vraisemblance :

Une fa√ßon d'√©valuer la performance d'un mod√®le, c'est de calculer sa vraisemblance, en statistique, elle indique la plausiblit√© du mod√®le vis √† vis de vraies donn√©es, par analogie, une histoire est vraisemblable lorsqu'elle est en accord avec des faits r√©els qui se sont vraiment d√©roul√©s.

<img width="521" alt="image" src="https://user-images.githubusercontent.com/78855647/168452602-80ad8122-58d8-4a8c-8539-cb52897bce2d.png">

Ainsi on calcule la vraisemblance de notre mod√®le, L = ‚Ñø P(Y=yi), pour i= 1 √† m, en utilisant la loi de Bernoulli, cela nous donne \:

<img width="557" alt="image" src="https://user-images.githubusercontent.com/78855647/168452618-9fc7df2c-dd0a-4a32-947b-6688dc14bdd4.png">

Si ce r√©sultat est proche de 1 (100%), ca signifiera que notre mod√®le est vraisemblable √† 100%, cad il colle parfaitement aux donn√©es que l'on consid√®re vraies.

<img width="541" alt="image" src="https://user-images.githubusercontent.com/78855647/168452629-8ed3bc18-7462-4eb3-b63e-bd6a4e176741.png">

Si L est proche de 0, √ßa voudrait dire que notre mod√®le est fortement invraisemblable, si ce mod√®le existe, cela signifierait que toutes les donn√©es dont nous disposons seraient en r√©alit√© fausses.

<img width="531" alt="image" src="https://user-images.githubusercontent.com/78855647/168452654-748d6f2a-eb04-4d63-b003-04fa0b97c054.png">

On doit donc trouver une astuce pour calculer cette vraisemblance sans pour autant converger vers 0. C'est pour √ßa qu'on utilise la fonction log vraisemblance, en effet la log passe de produit √† une somme \:

<img width="566" alt="image" src="https://user-images.githubusercontent.com/78855647/168452671-0166ff4e-fe99-4bf3-a61f-22e547284ba1.png">

Le passage en log vraisemblance ne fausse absolument pas les calculs afin de trouver les valeurs de W et b qui maximisent la log vraisamblence, car en effet la fonction log et monotone croissante \:

<img width="384" alt="image" src="https://user-images.githubusercontent.com/78855647/168452682-68dfa19d-4ca7-4469-86c3-649600dd7f43.png">
<img width="580" alt="image" src="https://user-images.githubusercontent.com/78855647/168452688-5232bcfa-1952-4292-ab0c-13361113d3cf.png">

Analytiquement on a :

<img width="524" alt="image" src="https://user-images.githubusercontent.com/78855647/168452697-7ffb4107-0f69-469c-9672-18ee7877db6a.png">

D'o√π l'explication de la fonction de co√ªt, le facteur 1/m est l√† pour normaliser le r√©sultat, et le signe (-) car en optimisation les algorithmes connus cherchent √† minimiser une fonction, c'est la m√™me chose car maximiser f(x) revient √† minimiser -f(x).

![image](https://user-images.githubusercontent.com/78855647/168452707-6591f211-aecb-44b1-aeb8-3f9386921fcf.png)

Pour ce probl√®me d'optimisation, on va utiliser l'algorithme de *la d√©scente de gradient.*










